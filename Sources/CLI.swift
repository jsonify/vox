import ArgumentParser
import Foundation

struct Vox: ParsableCommand {
    static let configuration = CommandConfiguration(
        commandName: "vox",
        abstract: "Extract audio from MP4 videos and transcribe to text using Apple's native speech recognition",
        usage: """
        vox <input-file> [options]
        
        Examples:
          vox video.mp4                              # Basic transcription to stdout
          vox video.mp4 -o transcript.txt            # Save to file
          vox video.mp4 --format srt                 # Generate SRT subtitles
          vox video.mp4 --timestamps --verbose       # Show timestamps and details
          vox presentation.mp4 --language en-US      # Specify language
          vox lecture.mp4 --fallback-api openai      # Use OpenAI as fallback
        """,
        discussion: """
        Vox prioritizes privacy by using Apple's native speech recognition when available,
        falling back to cloud APIs only when specified or when native recognition fails.
        
        Supported output formats: txt (default), srt, json
        Supported languages: en-US, en-GB, es-ES, fr-FR, de-DE, and more
        
        For more information, visit: https://github.com/jsonify/vox
        """,
        version: "1.0.0"
    )

    @Argument(help: "Path to MP4 video file to transcribe")
    var inputFile: String

    @Option(name: [.short, .long], help: "Save transcription to file (default: output to stdout)")
    var output: String?

    @Option(name: [.short, .long], help: "Output format: txt (plain text), srt (subtitles), json (structured data)")
    var format: OutputFormat = .txt

    @Option(name: [.short, .long], help: "Language code for transcription (e.g., en-US, es-ES, fr-FR)")
    var language: String?

    @Option(help: "Cloud API to use when native transcription fails: openai, revai")
    var fallbackApi: FallbackAPI?

    @Option(help: "API key for fallback cloud service (or set OPENAI_API_KEY/REVAI_API_KEY env var)")
    var apiKey: String?

    @Flag(name: [.short, .long], help: "Show detailed progress and processing information")
    var verbose = false

    @Flag(help: "Skip native transcription and use cloud API directly")
    var forceCloud = false

    @Flag(help: "Include timestamps in output (shows when each word/phrase was spoken)")
    var timestamps = false
  
    @Flag(help: "Include speaker identification in output (when available)")
    var speakers = false

    @Flag(help: "Include confidence scores showing transcription accuracy")
    var confidence = false

    @Flag(help: "Use detailed text format with comprehensive metadata")
    var detailed = false

    @Option(help: "Seconds of silence to create paragraph breaks (default: 2.0)")
    var paragraphBreak: Double = 2.0

    @Option(help: "Maximum line width for text wrapping (default: 80)")
    var lineWidth: Int = 80

    func run() throws {
        try validateInputs()
        configureLogging()
        displayStartupInfo()
        try processAudioFile()
    }

    private func validateInputs() throws {
        // Check if input file exists
        guard FileManager.default.fileExists(atPath: inputFile) else {
            throw VoxError.invalidInputFile(inputFile)
        }
        
        // Check if input file is readable
        guard FileManager.default.isReadableFile(atPath: inputFile) else {
            throw VoxError.permissionDenied(inputFile)
        }
        
        // Check file extension
        let fileExtension = URL(fileURLWithPath: inputFile).pathExtension.lowercased()
        guard fileExtension == "mp4" || fileExtension == "m4v" || fileExtension == "mov" else {
            throw VoxError.unsupportedFormat(fileExtension)
        }
        
        // Check if output directory exists and is writable (if output is specified)
        if let outputPath = output {
            let outputURL = URL(fileURLWithPath: outputPath)
            let outputDir = outputURL.deletingLastPathComponent()
            
            if !FileManager.default.fileExists(atPath: outputDir.path) {
                throw VoxError.invalidOutputPath("Directory does not exist: \(outputDir.path)")
            }
            
            if !FileManager.default.isWritableFile(atPath: outputDir.path) {
                throw VoxError.permissionDenied(outputDir.path)
            }
        }
        
        // Check if API key is required but missing
        if forceCloud && fallbackApi != nil && apiKey == nil {
            let envKey = fallbackApi == .openai ? "OPENAI_API_KEY" : "REVAI_API_KEY"
            if ProcessInfo.processInfo.environment[envKey] == nil {
                throw VoxError.apiKeyMissing(fallbackApi?.rawValue ?? "cloud service")
            }
        }
    }

    private func configureLogging() {
        Logger.shared.configure(verbose: verbose)
        
        if verbose {
            Logger.shared.info("Vox CLI - Audio transcription tool", component: "CLI")
            Logger.shared.info("Input file: \(inputFile)", component: "CLI")
            Logger.shared.info("Output format: \(format)", component: "CLI")

            if let output = output {
                Logger.shared.info("Output file: \(output)", component: "CLI")
            }

            if let language = language {
                Logger.shared.info("Language: \(language)", component: "CLI")
            }

            if let fallbackApi = fallbackApi {
                Logger.shared.info("Fallback API: \(fallbackApi)", component: "CLI")
            }

            if forceCloud {
                Logger.shared.info("Using cloud transcription (forced)", component: "CLI")
            } else {
                Logger.shared.info("Using native transcription with fallback", component: "CLI")
            }

            if timestamps {
                Logger.shared.info("Timestamps enabled", component: "CLI")
            }
        }
    }

    private func displayStartupInfo() {
        if !verbose {
            print("üé§ Vox - Transcribing \(inputFile)...")
        }
        
        if verbose {
            Logger.shared.info("üé§ Vox - Starting transcription", component: "CLI")
            Logger.shared.info("Input: \(inputFile)", component: "CLI")
            Logger.shared.info("Output: \(output ?? "stdout")", component: "CLI")
            Logger.shared.info("Format: \(format)", component: "CLI")
            
            if let language = language {
                Logger.shared.info("Language: \(language)", component: "CLI")
            }
            
            if forceCloud {
                Logger.shared.info("Mode: Cloud transcription (forced)", component: "CLI")
            } else {
                Logger.shared.info("Mode: Native transcription with cloud fallback", component: "CLI")
            }
            
            if timestamps {
                Logger.shared.info("Including timestamps", component: "CLI")
            }
        }
    }

    private func processAudioFile() throws {
        let audioFile = try extractAudio()
        let transcriptionResult = try transcribeAudio(audioFile)
        
        displayResults(transcriptionResult)
        saveOutput(transcriptionResult)
        cleanup(audioFile)

        displayCompletionMessage(transcriptionResult)
    }

    private func extractAudio() throws -> AudioFile {
        let audioProcessor = AudioProcessor()
        let progressDisplay = ProgressDisplayManager(verbose: verbose)

        let semaphore = DispatchSemaphore(value: 0)
        var processingError: Error?
        var extractedAudioFile: AudioFile?

        if verbose {
            Logger.shared.info("üéµ Extracting audio from: \(inputFile)", component: "CLI")
        }

        audioProcessor.extractAudio(
            from: inputFile,
            progressCallback: { progressReport in
                progressDisplay.displayProgress(progressReport)
            },
            completion: { result in
                switch result {
                case .success(let audioFile):
                    if self.verbose {
                        Logger.shared.info("‚úÖ Audio extraction completed successfully", component: "CLI")
                    }
                    self.displayAudioExtractionSuccess(audioFile)
                    extractedAudioFile = audioFile

                case .failure(let error):
                    Logger.shared.error("‚ùå Audio extraction failed: \(error.localizedDescription)", component: "CLI")
                    processingError = error
                }

                semaphore.signal()
            }
        )

        semaphore.wait()

        if let error = processingError {
            throw error
        }

        guard let audioFile = extractedAudioFile else {
            throw VoxError.processingFailed("Failed to extract audio file")
        }

        return audioFile
    }

    private func displayAudioExtractionSuccess(_ audioFile: AudioFile) {
        if verbose {
            Logger.shared.info("‚úÖ Audio extracted successfully", component: "CLI")
            Logger.shared.info("  Format: \(audioFile.format.codec)", component: "CLI")
            Logger.shared.info("  Sample Rate: \(audioFile.format.sampleRate) Hz", component: "CLI")
            Logger.shared.info("  Channels: \(audioFile.format.channels)", component: "CLI")
            Logger.shared.info("  Duration: \(String(format: "%.2f", audioFile.format.duration)) seconds", component: "CLI")

            if let bitRate = audioFile.format.bitRate {
                Logger.shared.info("  Bit Rate: \(bitRate) bps", component: "CLI")
            }

            if let tempPath = audioFile.temporaryPath {
                Logger.shared.info("  Temporary file: \(tempPath)", component: "CLI")
            }
        }
    }

    private func transcribeAudio(_ audioFile: AudioFile) throws -> TranscriptionResult {
        let transcriptionManager = TranscriptionManager(
            forceCloud: forceCloud,
            verbose: verbose,
            language: language,
            fallbackAPI: fallbackApi,
            apiKey: apiKey,
            includeTimestamps: timestamps
        )

        if verbose {
            Logger.shared.info("üó£Ô∏è Starting transcription...", component: "CLI")
        }

        return try transcriptionManager.transcribeAudio(audioFile: audioFile)
    }

    private func displayResults(_ result: TranscriptionResult) {
        let displayManager = ResultDisplayManager(forceCloud: forceCloud, timestamps: timestamps)
        displayManager.displayTranscriptionResult(result)
    }

    private func saveOutput(_ result: TranscriptionResult) {
        guard let outputPath = output else { return }

        do {
            let outputWriter = OutputWriter()

            // Configure formatting options based on CLI flags
            if format == .txt {
                let textOptions = TextFormattingOptions(
                    includeTimestamps: timestamps,
                    includeSpeakerIDs: speakers,
                    includeConfidenceScores: confidence,
                    paragraphBreakThreshold: paragraphBreak,
                    sentenceBreakThreshold: 0.8,
                    timestampFormat: .hms,
                    confidenceThreshold: 0.7,
                    lineWidth: lineWidth
                )

                // Write with validation using OutputWriter
                let successConfirmation = try outputWriter.writeTranscriptionResult(
                    result, 
                    to: outputPath, 
                    format: format, 
                    textOptions: textOptions
                )
                
                displaySuccessConfirmation(successConfirmation)
            } else {
                // Use OutputWriter for SRT and JSON with validation
                let successConfirmation = try outputWriter.writeTranscriptionResult(
                    result, 
                    to: outputPath, 
                    format: format
                )
                
                displaySuccessConfirmation(successConfirmation)
            }
        } catch {
            Logger.shared.error("Failed to save output: \(error.localizedDescription)", component: "CLI")
            Logger.shared.error("‚ùå Failed to save output: \(error.localizedDescription)", component: "CLI")
        }
    }

    private func displaySuccessConfirmation(_ confirmation: SuccessConfirmation) {
        // Display success message
        Logger.shared.info("‚úì \(confirmation.message)", component: "CLI")
        
        // Display validation status if verbose
        if verbose {
            let report = confirmation.validationReport
            Logger.shared.info("  Validation Status: \(report.overallStatus.rawValue)", component: "CLI")
            Logger.shared.info("  File Size: \(confirmation.fileSize) bytes", component: "CLI")
            Logger.shared.info("  Processing Time: \(String(format: "%.3f", confirmation.processingTime))s", component: "CLI")
            Logger.shared.info("  Validation Time: \(String(format: "%.3f", report.validationTime))s", component: "CLI")
            
            // Display any validation issues
            if !report.formatValidation.issues.isEmpty {
                Logger.shared.warn("  Format Issues: \(report.formatValidation.issues.joined(separator: ", "))", 
                                   component: "CLI")
            }
            if !report.integrityValidation.issues.isEmpty {
                Logger.shared.warn("  Integrity Issues: \(report.integrityValidation.issues.joined(separator: ", "))", 
                                   component: "CLI")
            }
            if !report.encodingValidation.issues.isEmpty {
                Logger.shared.warn("  Encoding Issues: \(report.encodingValidation.issues.joined(separator: ", "))", 
                                   component: "CLI")
            }
        }
    }

    private func cleanup(_ audioFile: AudioFile) {
        let audioProcessor = AudioProcessor()
        audioProcessor.cleanupTemporaryFiles(for: audioFile)
    }
    
    private func displayCompletionMessage(_ result: TranscriptionResult) {
        if verbose {
            Logger.shared.info("‚úÖ Transcription completed successfully!", component: "CLI")
            Logger.shared.info("  Duration: \(String(format: "%.2f", result.duration)) seconds", component: "CLI")
            Logger.shared.info("  Words: ~\(result.text.split(separator: " ").count)", component: "CLI")
            Logger.shared.info("  Processing time: \(String(format: "%.2f", result.processingTime)) seconds", component: "CLI")
            Logger.shared.info("  Engine: \(result.engine.rawValue)", component: "CLI")
            
            if let output = output {
                Logger.shared.info("  Output saved to: \(output)", component: "CLI")
            }
        } else {
            if let output = output {
                print("‚úÖ Transcription complete! Output saved to: \(output)")
            } else {
                print("‚úÖ Transcription complete!")
            }
        }
    }
}
